{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginalizing over long-term velocity trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New with v0.3, The Joker now supports sampling over polynomial, long-term velocity trends. In this example, we'll walk through a demo of how to set up and run the sampler while allowing for a quadratic (in time), long-term trend to the velocity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from thejoker.data import RVData\n",
    "from thejoker.sampler import JokerParams, TheJoker\n",
    "from thejoker.plot import plot_rv_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, I've already pre-generated some simulated data that we're going to use -- the true parameters of the main orbit are in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_P = 61.1166 * u.day\n",
    "true_e = 0.0324"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are provided in-line in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Time([55812.875, 55613.374, 55767.244, 55860.052,\n",
    "          55901.232, 55584.778, 55706.921, 55628.590], \n",
    "         format='mjd', scale='tcb')\n",
    "rv = [432.67367, 407.14526, 424.64327, 421.69321, \n",
    "      418.64374, 414.52811, 420.76149, 422.84962] * u.km/u.s\n",
    "rv_err = [25, 25, 25, 25, 25, 25, 25, 25] * u.m/u.s\n",
    "data = RVData(t, rv, stddev=rv_err)\n",
    "_ = data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the range of dates of the data, we'll set the period range to be somewhat restricted, since we don't need to consider period ranges much longer than the span of the data. To start with, we'll run the sampler in the default mode, which only tries to infer a constant offset (systemic) velocity for the system (i.e. no trend):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = JokerParams(P_min=2*u.day, P_max=1024*u.day,\n",
    "                     linear_par_Lambda=np.diag([1e2, 1e2])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joker = TheJoker(params)\n",
    "samples = joker.rejection_sample(data, n_prior_samples=2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_rv_curves(samples, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one sample was returned, and it's not a very good fit to the data. This is because the data were generated from a hierarchical triple system, but fit as a two-body system: in this case, the true system consists of an inner, short-period binary and an outer much longer term orbit. Let's now try generating Keplerian orbit samples for the inner binary, while including a polynomial trend in velocity to capture the long-term trend from the outer companion. To do this, we specify the number of polynomial trend coefficients to sample over: 1 is constant, 2 is linear, 3 is quadratic, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_trend = JokerParams(P_min=2*u.day, P_max=1024*u.day,\n",
    "                           linear_par_Lambda=np.diag([1e2, 1e2, 1e0])**2,\n",
    "                           poly_trend=2)\n",
    "\n",
    "joker_trend = TheJoker(params_trend)\n",
    "samples_trend = joker_trend.rejection_sample(data, n_prior_samples=2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_rv_curves(samples_trend, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, this does a much better job of fitting the data. But how do the system parameters compare to the true values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_trend['P'], true_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_trend['e'], true_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though only one sample is returned here, they are very close to the truth! To generate more samples for this system, we would either need to greatly increase the number of prior samples, or hope that the posterior is unimodal and run standard MCMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting priors on the trend parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, when generating posterior samples in the trend parameters, we adopt very wide Gaussian priors on each parameter individually (i.e. we assume they are uncorrelated). You can specify the Gaussian widths (or covariances) if you want to limit the trend parameters. For example, using the above data, we may want to try using a quadratic trend in velocity, but we may want to limit the magnitude of the quadratic coefficient (which has units velocity / day^2). Here we'll put a stronger prior on the linear and quadratic coefficients by specifying the standard deviations of the Gaussian priors on those parameters. We then construct an inverse-variance matrix for the linear parameters Gaussian prior using these standard deviations. The first parameter in the matrix is for the velocity amplitude, K, and the others are for the trend coefficients (constant, linear, quadratic for the example below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_par_sigmas = np.array([1e3, 1e3, 1e0, 1e-4]) # standard deviations\n",
    "linear_par_Lambda = np.diag(linear_par_sigmas**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_trend_prior = JokerParams(P_min=2*u.day, P_max=1024*u.day,\n",
    "                                 poly_trend=3, \n",
    "                                 linear_par_Lambda=linear_par_Lambda)\n",
    "\n",
    "joker_trend_prior = TheJoker(params_trend_prior)\n",
    "samples_trend_prior = joker_trend_prior.rejection_sample(data, \n",
    "                                                         n_prior_samples=2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_rv_curves(samples_trend_prior, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
