> Note: The authors will probably be able to infer my identity from these
> remarks. I am fine with that.

> This was an interesting and entertaining read. Price-Whelan et al have
> developed an innovative (and rather crazy, or, more charitably, ambitious)
> approach to sampling the posterior distribution for orbital parameters given
> radial velocity measurements. The goal is to use this to "measure the
> undetectable" (a recurring theme in some of the authors' work) - to use
> hierarchical inference to make statements about the population when each
> object in that population has it properties only poorly constrained.

> Overall, I am impressed that this works, and I would like to see the paper
> published eventually. The plots are beautiful and help reinforce the ideas
> very well (they illustrate generic features of this data analysis problem
> very clearly). But I have a few criticisms, listed below.

We thank the referee for a constructive and useful report! We hope we have
addressed the referee's concerns; we've updated the manuscript (in red where
changes have been made) and added responses below in-line.

> - What is the origin and significance of the title "The Joker"? Forgive me
>   for being dense, but I don't get it.

It's short for Johannes Kepler.

> - Regarding the above point about measuring the undetectable, it might be
>   worth referring to one or two papers outside of exoplanets where that kind
>   of thing has been done.

HOGG TODO

> - Some important previous work has not been cited, which might give some
>   readers an inaccurate impression that this problem hadn't been solved
>   before. Particularly, the work of Phil Gregory comes to mind here. He has
>   been paying attention to multimodality in the posterior distribution for
>   exoplanet parameters since 2005 and while I don't agree with a few aspects
>   of his work, it is very canonical in this area and should be referenced. In
>   the section on scheduling follow-up observations, I suggest Loredo (2004)
>   [https://arxiv.org/abs/astro-ph/0409386].

APW TODO

> - There is no clear indication of how fast this method is or how it might to
>   compare to competing ones. At some points, mentions of huge numbers of
>   Monte Carlo samples appear. How many likelihood evaluations are needed in
>   total to analyse one time series? How might this compare to other
>   approaches? The main advantage of "The Joker" is probably its usability
>   (given the authors' reputations in the realm of software). Its speed might
>   be another, but the paper doesn't make that clear one way or the other.

APW TODO

> - In the abstract, you should explicitly state that you condition on one
>   planet (or stellar companion), rather than expecting the reader to infer it
>   from your sentences about the number of orbital parameters.

We updated the abstract to make this more explicit.

> - Introduction, paragraph four. "explore these highly multimodal functions".
>   Change functions -> distributions.

Changed.

> - Introduction, paragraph four. "guarantees of correctness" - this is an
>   awkward thing to claim. MCMC has guarantees of correctness in the limit t
>   -> infinity. The Brewer and Donovan method is an example of MCMC so
>   inherits this "guarantee" but does it better in finite time (in a
>   multimodal situation) than Metropolis sampling of the posterior would. I
>   don't see how your rejection sampling method would have more guarantees.
>   Could you please clarify this.

HOGG TODO

> - Section 1, final paragraph: I like the structure of the article very much.

Thanks very much for your comments!

> - Section 2, second bullet point: "Our analysis allows the effective mass ...
>   to go to zero". With finite probability? If so, say so. If not, remove the
>   statement (or reword to "to be close to zero").

Changed.

> - Related to the above point - I just tried to find the prior for K but could
>   not. Where is it specified?

We had defined it (in words) below Equation 11, but we have moved the
discussion about the priors on the linear parameters to the same paragraph as
Equations 5-9 (which define the other priors.)

> - Section 2, third bullet point: I am vehemently opposed to the language of
>   quantities as "having been drawn from" probability distributions, except
>   when talking about computer code that calls an RNG. I am fighting a losing
>   battle on this, I suppose.

We changed "draws" to "samples".

> - Page 4. In my opinion "Simple Monte Carlo" and Rejection Sampling are
>   different things. Maybe I'm wrong on this, but I feel like the former is
>   estimating an expectation E_f(g(x)) by sampling from f and averaging g (no
>   rejection or filtering of samples takes place), whereas the latter is what
>   you're actually using. Please correct either me or the article.

HOGG TODO: (What the ref says is my understanding too, but you love the phrase
Simple Monte Carlo! - APW)

> - What does it mean to "densely" sample? Do you just mean you generate a lot
>   of points?

We mean to generate a lot of points that resolve the smallest peaks that occur
because of the time-sampling. We have added a statement to clarify.

> - End of page four, inside step 1: likelihood value -> marginal likelihood
>   value (and perhaps also add "given the NONLINEAR parameters" inside the
>   parentheses)

Changed.

> - Page 5, the paragraph after the steps. The article states "If the original
>   sampling...is dense enough that many samples survive the rejection step,
>   the surviving samples constitute a fair sampling". I believe this is false.
>   I assume a 'fair sampling' means that the prior probability distribution
>   for where points will be generated, conditional on the target density, is
>   equal to the target density. The given procedure does not have this
>   property except in the limit N -> infinity. Counterexample: uniform prior
>   in high dimensions, likelihood function a mixture of two isolated gaussians
>   with very different widths but comparable posterior masses. Most generated
>   points will fall into the wide gaussian. You will get lots of points with
>   likelihood comparable to the maximum seen. But if you waited 100 more
>   years, you'd eventually see a point in the narrow gaussian which would
>   render all of your other points rejected. That said, I think you are
>   *reasonably* safe in practice.

HOGG TODO: (I think he's just confused by the terminology? Don't all samplings
converge to the target distribution as N->infinity, and not when N is finite? -
APW)

> - Equation 9. The notation p(ln s^2) = something with subscript s is
>   confusing. How should I read this? The prior for ln(s) is normal? If so,
>   why square the s on the left hand side?

As a rule, we generally like to think in terms of variances instead of
root-variances, but we agree that here the choice is arbitrary and, for the sake
of notation, we have updated the equation.

> - Page 6, middle paragraph "expected from information-theory (sampling
>   theorems) perspective" I had always thought these were separate subjects
>   (information theory is about entropies and so on, sampling theorems are
>   about signal processing and discrete FFTs etc). I'm sure there are
>   connections between them though.

HOGG TODO

> - Page 6 final sentence typo: intialization -> initialization

Fixed.

> - Page 7, step 2. Why 2^16 steps? Are these steps loops over the walkers? Be
>   explicit so we can estimate the number of likelihood evaluations occurring.

This is an arbitrary choice and in practice (as usual) convergence statistics
can be computed for the chains to assess whether this is insufficient or
overkill. We added a statement to note this.

> - The demonstration sections on different datasets, and the discussion around
>   them, was quite good.

Thanks!

> - Section 3.1, first paragraph. (e.g., the truth): e.g., -> i.e.,

Fixed.

> - Section 3.2, final paragraph: Most of what happened here would have been
>   predicted by anyone familiar with Bayesian inference, and is not specific
>   to The Joker. It is still useful to state these things, but can you try to
>   moderate the wording here?

Could you highlight what specifically you would like to see moderated? Thanks!

> - Section 3.3, final paragraph: "day and re-use these ...": day -> days

Fixed.

> - Page 25: "If lots of samples survive the rejection step, the posterior ha
>   been sampled" - See above. I think this is false.

HOGG TODO: (related to point above)

> - Final paragraph: "There are no data sets with perfectly gaussian noise".
>   This sentence propagates a misunderstanding. Using p(data | params) ~
>   gaussian is an assumption about the prior information, not about the data.
>   It is an assumption that often *doesn't take into account relevant
>   information* and needs to be questioned on that basis. But the problems
>   that gaussian assumptions cause have nothing to do with "the data sets
>   having non-gaussian noise".

HOGG TODO: (isn't this saying the same thing, but from a different angle? - APW)

> - Final paragraph: sentence ending "should mitigate" is awkward. I agree it
>   mitigates. Can you tidy up the sentence?

We have rephrased this sentence.

> - Final paragraph: "There is nothing we can do simply here". I haven't
>   written down the maths to see if this works out, but replacing your s
>   parameter with something that puts a mixture of scales into p(data |
>   params) (e.g. making it a scale mixture of two gaussians) might be
>   tractable.

HOGG TODO: (I guess this would be possible...but worth mentioning in the paper?
IDK - APW)
