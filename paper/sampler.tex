\documentclass[manuscript, letterpaper]{aastex6}

% to-do list
% ----------
% - zeroth draft
% - search for occurrences of HOGG, DWH, APW, DFM, HWR in the text to make sure all issues are addressed.

% style notes
% -----------
% - This file generates by Makefile; don't be typing ``pdflatex'' or some bullshit.
% - Line break between sentences to make the git diffs readable.
% - Simple Monte Carlo gets a capital S to indicate that it is a defined thing.
% - Use \, as a multiply operator.
% - Reserve () for function arguments; use [] or {} for outer shit.
% - Always prior pdf or posterior pdf, never prior or posterior (that's your arse).
% - Use \sectionname not Section, \figname not Figure, \documentname not Article or Paper or paper.

\include{gitstuff}
\include{aastexmods}

% packages
\definecolor{cbblue}{HTML}{3182bd}
\usepackage{microtype}  % ALWAYS!
\usepackage{amsmath}
\hypersetup{backref,breaklinks,colorlinks,urlcolor=cbblue,linkcolor=cbblue,citecolor=black}

% define macros for text
\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\acronym}[1]{{\small{#1}}}
\newcommand{\apogee}{\project{\acronym{APOGEE}}}
\newcommand{\sdssiii}{\project{\acronym{SDSS-III}}}
\newcommand{\samplername}{\project{The~Joker}}
\newcommand{\emcee}{\project{emcee}}
\newcommand{\dr}{\acronym{DR13}}
\newcommand{\documentname}{\textsl{Article}}
\newcommand{\sectionname}{Section}
\newcommand{\figname}{Figure}
\newcommand{\eqname}{Equation}

% define macros for math
\newcommand{\asini}{\ensuremath{a_1\,\sin i}}
\newcommand{\given}{\,|\,}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\transpose}[1]{{#1}^{\mathsf{T}}}
\newcommand{\inv}[1]{{#1}^{-1}}
\newcommand{\msun}{\mathrm{M}_\odot}
\newcommand{\rsun}{\mathrm{R}_\odot}
\newcommand{\kms}{\mathrm{km}~\mathrm{s}^{-1}}
\newcommand{\mps}{\mathrm{m}~\mathrm{s}^{-1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}

% For experiments
\newcounter{expcounter}
\stepcounter{expcounter}

% TODO
\newcommand{\todo}[1]{{\color{red}TODO: #1}}

\begin{document}\sloppy\sloppypar\raggedbottom\frenchspacing % trust me

\title{\samplername: A custom Monte Carlo sampler \\
  for binary-star and exoplanet radial velocity data}
\author{Adrian~M.~Price-Whelan\altaffilmark{\pu,\adrn},
        David~W.~Hogg\altaffilmark{\ccpp,\mpia},
        Daniel~Foreman-Mackey\altaffilmark{\uw,\sagan},
        Hans-Walter~Rix\altaffilmark{\mpia}
}

% Affiliations
\newcommand{\pu}{1}
\newcommand{\adrn}{2}
\newcommand{\ccpp}{3}
\newcommand{\mpia}{4}
\newcommand{\uw}{5}
\newcommand{\sagan}{6}

\altaffiltext{\pu}{Department of Astrophysical Sciences,
                   Princeton University, Princeton, NJ 08544, USA}
\altaffiltext{\adrn}{To whom correspondence should be addressed:
                     \texttt{adrn@princeton.edu}}
\altaffiltext{\ccpp}{Center for Cosmology and Particle Physics,
                     Department of Physics,
                     New York University, 4 Washington Place,
                     New York, NY 10003, USA}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie,
                     K\"onigstuhl 17, D-69117 Heidelberg, Germany}
\altaffiltext{\uw}{Astronomy Department, University of Washington,
                   Seattle, WA 98195, USA}
\altaffiltext{\sagan}{Sagan Fellow}

\begin{abstract}
% Context
Given sparse or low-quality radial-velocity measurements of a star, there are
often many qualitatively different stellar or exoplanet companion orbit models
that are consistent with the data.
The consequent multimodality of the likelihood function leads to extremely
challenging search, optimization, and MCMC posterior sampling in the space of
orbital parameters.
% Aims
Here we create a custom-built Monte Carlo sampler that can produce a posterior
sampling for orbital parameters given any number of noisy radial-velocity
measurements~--~even when the likelihood function is poorly behaved.
% Methods
The six standard orbital parameters can be split into the four non-linear
parameters (period, eccentricity, argument of pericenter, phase) and two linear
parameters (velocity amplitude and barycenter velocity).
We capitalize on this separability and build a variant of Simple Monte Carlo
sampling, in which we densely sample the non-linear orbital parameters, and
perform rejection sampling using a marginalized likelihood, marginalizing out
the linear orbital parameters.
In the case of sparse or uninformative data, the sampling obtained by the Simple
Monte Carlo is generally multimodal and dense.
With informative data, the sampling is generally unimodal but insufficient.
In the unimodal case, we follow the Simple Monte Carlo with standard MCMC to
make the sampling more substantial.
% Results
The method produces correct samplings in orbital parameters for data sets
that include as few as three noisy time points.
\samplername\ can therefore be used to (1) verify that the likelihood function
is unimodal \todo{(None of the datasets will actually have unimodal
likelihoods\ldots what does this mean?)} for a given set of data, and (2)
produce proper samplings of multimodal pdf to use in hierarchical modeling
(e.g., population modeling).
We give some examples that show how the posterior probability depends extremely
strongly on the number and time coverage of the observations and their
uncertainties.
\end{abstract}

\keywords{
  binaries: spectroscopic
  ---
  methods: data analysis
  ---
  methods: statistical
  ---
  planets and satellites: fundamental parameters
  ---
  surveys
  ---
  techniques: radial velocities
}

\section{Introduction} \label{sec:intro}

Precise radial-velocity measurements of stars have transformed
astrophysics in the last decades:
They have permitted the discovery of the first planets around other stars,
including especially the unanticipated but common ``hot Jupiters,''
and have been used to discover or confirm hundreds
of planets (for a review, see \citealt{Udry:2007}).
Radial velocity measurements have also been used to find substellar,
degenerate, and black-hole companions to more normal stars, and hold
the promise of delivering the full population statistics for binary
(and trinary) star systems (e.g., \citealt{Raghavan:2010,
Tokovinin:2014,Troup:2016}).

With large stellar spectroscopic surveys operating or under
construction, we expect to have good quality spectra for millions
of stars in the next few years.
Most of these surveys have at least some targets---and many have many
targets---that are observed multiple times (e.g., \citealt{Majewski:2015}).
These surveys can (as an auxilliary or primary goal of their observing
strategies) generate discoveries of planetary, substellar, and stellar
companions.
These discoveries, in turn, will feed population inferences, follow-up
programs, and projects to refine precise stellar models.

However, when radial-velocity observations are not designed with
unambiguous detection and discovery in mind, usually there are
multiple possible binary-star (orbit) models that are consistent with any
modest number of radial-velocity measurements that show stellar
acceleration.
That is, a small number of radial velocity measurements---even when the
uncertainties are small---will lead to posterior beliefs about companion
orbits and masses that put substantial plausibility onto multiple
qualitatively different solutions.
This is then reflected in a likelihood function that is highly multi-modal in
the relevant parameter spaces (e.g., Keplerian orbital parameters).
While the problem has of course been recognized for a long time, there are
currently no methods known for exploring these highly multimodal functions and
delivering correct posterior samplings and reliable probabilistic statements
about detection and characterization.
\todo{Why are we not happy with nested sampling?}

Here we make an attempt at correcting this problem.
Our approach is to build custom posterior sampling methods that capitalize on
the structure of the binary-star (or star--exoplanet) kinematics to generate
robust samplings also of multiple solutions at manageable computational cost.
In what follows, we use the term ``binary'' for any system with an observed
source (the primary, e.g., a star), whose radial velocity variations are
explained through gravitational two-body interactions with another object (the
companion, e.g., star, exoplanet, stellar remnant); i.e. we restrict our
analysis to single-line spectroscopic binary systems.

The structure of this \documentname\ is as follows:
We state our assumptions and implementation approach, and demonstrate that we
have a method that is not only robust, but essentially always correct under
those assumptions.
\todo{HOGG: I know that you like this ``provably correct'' terminology but I
(DFM) really think it doesn't add anything to the discussion.}
We perform experiments with the method to understand its properties and
limitations.
We finish by discussing the astrophysical applicability and potential of the
method.
We discuss the changes we would have to make if we weakened our assumptions, or
if we don't weaken our assumptions but they indeed prove to be far from correct.

\section{Assumptions and method} \label{sec:method}

In order to set up a well-posed problem and build a path to a definite solution,
we make a set of non-trivial assumptions about the stellar systems we will use
and observations thereof.
Ultimately, we assume that the radial velocity curve of a single-line
spectroscopic binary system can be specified by six parameters
(\citealt{Kepler:1609}).
Here we adopt a parameterization similar to \citealt{Murray:2010}:
$P$, $e$, $\phi_0$, $\omega$, $K$, and $v_0$, which are the period,
eccentricity, pericenter phase and argument, velocity semi-amplitude, and the
barycenter velocity.
As is well-known, this does not fully specify the binary system itself, because
of the $\sin{i}$ and mass function degeneracies.
To proceed, we assume that
\begin{itemize}\itemsep0ex  % <- #yourefired
\item we have measurements of the radial velocity of a
  star, and that the time dependence of the expectation of that radial
  velocity is well described by the gravitational orbit of a pair of
  point masses (the two-body problem). We assume that the times are
  (effectively) perfectly known, and in an inertial frame (for
  example, Solar-System barycenter Julian date).
  Here we only consider the case of a single-line spectroscopic binary system,
  where we do not have measurements of the companion's orbit.
\item  each star has exactly one companion, and that the
  radial-velocity measurements are not contaminated by nor affected by
  any other bodies. Since we permit the effective mass of the
  exactly-one companion to go to zero, this assumption is really that
  the star has zero or one companion.
\item the noise contributions to individual radial-velocity measurements are
  well described as draws from zero-mean normal (Gaussian) distributions with
  correctly known variances convolved with a zero-mean normal distribution with
  an additional ``jitter'' variance, $s^2$. We assume that there are no outliers
  beyond this flexible noise model.
\item we can put a particular, fairly sensible
  prior probability density functions on all the orbital parameters,
  described below.
\end{itemize}
Each of these assumptions could be challenged: in particular we expect some stars
to have additional companions, and we expect there to be outliers and
unaccounted sources of noise.
We will return to these assumptions, and the consequences of relaxing them, in
\sectionname~\ref{sec:discussion}.

The radial velocity $v$ at time $t$ is then given by (see also \eqname~63 in
\citealt{Murray:2010})
\begin{equation}
  v(t;\bs{\theta}) = v_0 + K\,[\cos(\omega + f) + e\,\cos\omega]
\end{equation}
where the $\bs{\theta}$ represents the free parameters, $f$ is the true anomaly
given by
\begin{equation}
  \cos f = \frac{\cos E - e}{1 - e\, \cos E}
\end{equation}
and the eccentric anomaly, $E$, must be solved for with the mean
anomaly, $M$,
\begin{align}
  M &= \frac{2\pi\, t}{P} - \phi_0\\
  M &= E - e\,\sin E \quad .
\end{align}
Of these parameters, four ($P$, $e$, $\omega$, $\phi_0$) are non-linearly
related to the radial-velocity expectation, and two ($K$, $v_0$) are
linearly related.
We additionally allow the jitter, $s^2$, to vary to partially account for
imperfect knowledge of the radial velocity uncertainties and any intrinsic
radial-velocity scatter; the jitter must also be treated as a non-linear
parameter.

With such a parameterization, the problem is then to construct the posterior pdf
for these seven parameters, accounting for the fact that the support of this pdf
may have very complex, multi-modal structure.

Fundamentally, the method we describe and demonstrate here is to perform
\emph{Simple Monte Carlo} in the non-linear parameters, and analytically
marginalize over the two linear parameters.
The method capitalizes on the following aspects of the problem structure:
\begin{itemize}\itemsep0ex
\item There are both linear and non-linear parameters, and we can
  treat them differently; in particular, it is possible to
  analytically marginalize the linear parameters (provided that the
  noise model is well-behaved and the prior probability is conjugate).
\item There is a finite, time-sampling-imposed minimum size or
  resolution---in the period---of any features in the
  likelihood function. That is, there cannot be arbitrarily narrow
  modes in the multimodal posterior pdf.
\end{itemize}

The method we refer to as Simple Monte Carlo is a specific case of
rejection-sampling (\citealt{TODO}) in which we densely sample from the prior
probability density function (prior pdf) and use the likelihood evaluated at
these samples as the rejection scalar.
In detail, the rejection step works as follows:
\begin{enumerate}\itemsep0ex
\item For each sample $j$ in the prior pdf sampling of the four non-linear
  parameters, there is a (linear, not logarithmic) likelihood value $L_j$ (a
  probability for the data given the parameters).
\item There is a maximum value $L_{\rm max}$ that is the largest value of
  $L_j$ found across all of the samples in the prior sampling.
\item For each sample $j$, choose a random number $r_j$ between 0 and
  $L_{\rm max}$
\item Reject the sample $j$ if $L_j < r_j$.
\item The number of samples that survive the rejection is (hereafter) $M$.
\end{enumerate}
Note that this algorithm is guaranteed to produce at least one
surviving sample; of course if only one sample survives (or any very
small number), the sampling is not guaranteed to be fair.
That said, if the original sampling of the prior pdf is dense enough
that many survive the rejection step, the surviving samples do
constitute a fair sampling from the posterior pdf.

Our prior pdf in the non-linear parameters is very simple:
\begin{align}
    p(\ln P) &= \mathcal{U}(\ln P_{\rm min}, \ln P_{\rm max})\\
    p(e) &= {\rm Beta}(a, b) = \frac{\Gamma(a+b)}{\Gamma(a) \, \Gamma(b)} \, e^{a-1} \, [1 - e]^{b-1}\\
    p(\omega) &= \mathcal{U}(0, 2\pi) ~ [{\rm rad}]\\
    p(\phi_0) &= \mathcal{U}(0, 2\pi) ~ [{\rm rad}]\\
    p(\ln s^2) &= \mathcal{N}(\mu_s, \sigma^2_s)
\end{align}
where $\mathcal{U}(x_1, x_2)$ is the uniform distribution over the domain $(x_1,
x_2)$, $\mathcal{N}(\mu, \sigma^2)$ is the normal distribution with mean $\mu$
and variance $\sigma^2$, and the prior pdf over eccentricity is the Beta
distribution with $a=0.867$, $b=3.03$ \citep{Kipping:2013}.

In \sectionname~\ref{sec:experiments} or in the subsections specific to the
different experiments we specify the values for hyperparameters $P_{\rm min}$,
$P_{\rm max}$, $\mu_s$, and $\sigma^2_s$.
In practice, the choice of $\mu_s$ and $\sigma^2_s$ can be tuned appropriately
depending on knowledge about intrinsic variability of the source or suspicions
about the reported uncertainties.
We sample the prior pdf directly and explicitly with standard
\project{numpy.random} calls (\citealt{Van-der-Walt:2011}).
In practice, we are usually required to take around $J=2^{28}$ samples (indeed,
a quarter billion samples) from the prior-pdf to produce sufficient final
samplings; in each experiment below, we state  the total number of prior samples
generated and the number of surviving samples.

The unmarginalized likelihood function $L$ is
\begin{equation}
\ln L = -\frac{1}{2}\,\sum_{n=1}^N \left[\frac{[v_n - v(t_n;\bs{\theta})]^2}{\sigma_n^2 + s^2}
 -\ln \left(s^2 + \sigma_n^2\right) \right] + \mathrm{constant}
\end{equation}
where $n$ indexes the individual data points $v_n$, $v(t)$ is the radial
velocity prediction at time $t$ given the orbital parameters $\bs{\theta}$, the
data-point times are the $t_n$, and $\sigma_n^2$ is the Gaussian noise variance
for data point $n$.
Note that the form of this likelihood function is set entirely by the
assumptions, given above.

We rejection-sample, however, using a marginalized likelihood, where we
analytically marginalize out the linear parameters ($K$, $v_0$).
We construct a $N \times 2$ design matrix consisting of a column of unit-$[K]$
predictions (given the non-linear parameters) and a column of ones.
We perform standard linear least-square fitting with this design
matrix to obtain the best-fit values for the two linear parameters,
and the standard $2\times 2$ linear-fitting covariance matrix $C_j$ for their
uncertainties.
With these, we can construct---for each prior sample---the marginalized
likelihood $Q_j$
\begin{equation}
\ln Q_j = -\frac{1}{2}\,\sum_{n=1}^N \left[\frac{[v_n - v(t_n;\bs{\theta})]^2}{\sigma_n^2 + s^2}
 -\ln \left(s^2 + \sigma_n^2\right) \right] -\frac{1}{2}\,\ln ||C_j||
 + \mathrm{constant}
\end{equation}
where the prediction $v(t_n;\bs{\theta}_j)$ is taken at the best-fit values of
the linear parameters given sample $j$ of the non-linear parameters, and the
log-determinant term ($\ln ||C_j||$) accounts for the volume in the
marginalization integral.
The marginalization assumes that the prior pdfs on the linear parameters
are very broad and Gaussian---or
at least very flat over the range of relevance---and that they do not depend
on the nonlinear parameters in any way (which is a substantial restriction;
see \sectionname~\ref{sec:discussion}).
These $Q_j$ are used in the rejection sampling algorithm described above
as Simple Monte Carlo.

There are three possible outcomes of this rejection sampling, based on two
thresholds:
We set a minimum number of samples $M_{\rm min}=128$.
We also set a period resolution $\Delta = [4\,P^2] / [2\pi\,T]$, (with
$P$ set to the median period across the surviving samples and $T$ set to
the epoch span of the data).
This $\Delta$ is an expansion of the period
resolution expected from an information-theory (sampling theorems) perspective
\todo{~HWR: this previous sentence sounds cool; what does it mean?}.
The three possible outcomes are:
\begin{itemize}\itemsep0ex
\item $M\geq M_{\rm min}$ samples survive the rejection.
  In this case, we are done.
\item $M<M_{\rm min}$ samples survive the rejection, and these samples have a
  root-variance (rms) in the period parameter $P$ that is smaller than $\Delta$
  (i.e. they give no indication of period ambiguity).
  In this case we assume that the posterior pdf is unimodal, and we use the
  surviving samples (or sample) to initialize a MCMC sampling using the \emcee\
  package (\citealt{Foreman-Mackey:2013}).
\item $M<M_{\rm min}$ samples survive the rejection, and these samples
  span a period range larger than $\Delta$.
  In this case, we iterate the Simple Monte Carlo procedure: We generate new
  prior-pdf samplings and rejection sample until the number of surviving samples
  is larger than $M_{\rm min}$.
  This is expensive.
\end{itemize}
When we trigger the intialization and operation of \emcee, we do the following:
\begin{enumerate}\itemsep0ex
\item Randomly generate $M_{\rm min}$ sets of parameters $\bs{\theta}_m$
  (linear and nonlinear parameters) in a small, Gaussian ball around
  the highest-$Q_j$ sample from the Simple Monte Carlo.
\item Run \emcee\ on this ensemble (with $M_{\rm min}$ walkers) for $2^{16}$
  steps.
\item Take the final state of the $M_{\rm min}$-element ensemble as a
  fair sampling of the posterior pdf.
\end{enumerate}
This procedure ensures that no matter what path we take, we end up with
at least $M_{\rm min}$ samples from the posterior for any input data.

Within the initial assumptions, this procedure results basically inevitably in a
correct parameter {\it pdf}, which is borne out in the numerical experiments in
the next section.
\todo{~HWR: the claim that this ALWAYS works is almost as much rooted in the
logic of the method than in the experiments. Is it not that our pdf sampling is
sufficiently dense that you cannot miss a relevant part of solution space?}


\section{Experiments and results} \label{sec:experiments}

In what follows, we use (1) simulated data with known properties and (2)
spectroscopic data from Data Release 13 (DR13;
\citealt{SDSS-Collaboration:2016}) of the Apache Point Obsevatory Galactic
Evolution Experiment (\apogee; \citealt{Majewski:2015}) in a series of
experiments that demonstrate the robustness and utility of \samplername.
\apogee\ is one of the four sub-surveys of the Sloan Digital Sky Survey-III
(SDSS-III; \citealt{Eisenstein:2011}) and utilized a new infrared spectrograph
to obtain moderate-resolution, H-band spectra for over 160,000 stars throughout
the Galaxy.
From these spectra, high-precision radial velocities, chemical abundances, and
stellar parameters have been derived and released as a part of DR13
(\citealt{Holtzman:2015,Nidever:2015}).

As a part of the observing strategy of \apogee, most stars are observed
multiple times and binned by day into ``visit'' spectra.
Though a typical star is only observed a few times, (1) at least one pair of
visits are separated by one month or longer, and (2) thousands of stars have
been observed more than 10 times (for a more detailed look at the cadence and
number of visits for \apogee\ stars, see \figname~1 in \citealt{Troup:2016}).
Radial velocities (and stellar parameters) are derived for each of the visit
spectra, affording a sparse and sporadic time-domain sampling of the radial
velocity variations of most stars in the survey.
This time-domain information was recently used to identify a sample of
candidate stellar and substellar companions to \apogee\ stars
(\citealt{Troup:2016}).

This search was conducted after data quality and data \emph{quantity} cuts that
were designed to keep the number of data points larger than the number of
parameters in the model.
In their case, the model parameters are six Keplerian orbital parameters plus a
long-term (linear) velocity trend (seven in total).
Under this criterion, stars with fewer than eight visits were rejected from
consideration, leaving $\approx$15,000 stars.
For each of the remaining stars, the radial velocity curves are searched for
significant periods, which are then used to initialize $\chi^2$ fits of a
Keplerian orbit using a custom least-squares fitter \todo{APW: cite De Lee even
though we don't use it?}.
In cases where multiple significant periods are found, the parameters obtained
from the fit with the best modified $\chi^2$ value are retained (modulo a
number of other considerations described in \sectionname~3.3.4 of
\citealt{Troup:2016}).

The complexity of this pipeline and logic needed to identify a single optimal
set of orbital parameters from a set of solutions highlights the fact that the
likelihood function for a Keplerian orbit model is generically multi-modal.
When there are few data points or poor phase coverage this is especially true.
While useful for searching for new candidate binaries, this pipeline does not
easily fit within hierarchical probabilistic modeling of the population of
companions.

\todo{APW: Update this to reflect new experiments}
In Experiment 1, we use DR13 data for an \apogee\ star with a companion
(identified by \citealt{Troup:2016}) to demonstrate that the posterior pdf over
Keplerian orbital parameters can be highly multi-modal by using \samplername\
to generate samples from this distribution.
In Experiment 2, we use DR13 data for an \apogee\ star with better radial
velocity phase coverage and more observations and show how the complexity of
the posterior pdf increases as data points are artificially deleted from the
analysis.

\subsection{Experiment~\arabic{expcounter}: Validation with simulated data}
\label{sec:validation}
\stepcounter{expcounter}

As a first demonstration, we generate fake radial velocity observations (with
uncertainties) that are consistent with our assumptions
(\sectionname~\ref{sec:method}), then sample from the posterior pdf over orbital
parameters with \samplername.
The eccentricity, period, and velocity semi-amplitude are chosen to be broadly
consistent with the typical sub-stellar companion found in recent analysis of
the \apogee\ data (\citealt{Troup:2016}), the angle parameters ($\omega$,
$\phi_0$) are sampled from a uniform distribution, and the barycenter velocity
is drawn from a zero-mean Gaussian with variance $\sigma^2 = (30~\kms)^2$.
The values of the parameters used for the simulated data (e.g., the truth) are:
$P = 103.71~{\rm day}$, $e = 0.313$, $\omega = 68.95^\circ$,
$\phi_0 = 223.96^\circ$, $K = 8.134~\kms$, $v_0 = 42.98~\kms$.
We uniformly sample 5 observation times over the interval $(0,1095)~{\rm day}$
imagining a 3-year survey with no observing strategy and arbitrarily set the
survey start date (in barycentric MJD) to be 55555.
The radial velocity measurement uncertainties are drawn from a uniform
distribution over the interval $(0.1, 0.2)~\kms$, motivated by the \apogee\
radial velocity uncertainties.

We perform two samplings as a validation of \samplername:
(a) we fix the jitter parameter $s^2 = 0$, i.e. we assume the uncertainties are
known perfectly and there is no intrinsic scatter, and (b) we sample over the
jitter parameter as well, setting $(\mu_s,\sigma^2_s) = (0,8)$ (note that these
are dimensionless because they set the scale of a Gaussian in $\ln s^2$).
We start by generating $J=2^{28}$ prior samples over the nonlinear parameters
with a period domain of $(P_{\rm min}, P_{\rm max}) = (16, 8192)~{\rm day}$ (see
\sectionname~\ref{sec:method}) and use these same prior samples for both runs.
For (a), 678 samples pass our rejection sampling step, and for (b), 580 samples
survive.

\figname~\ref{fig:validation-rv} shows the simulated data (black points) along with
the true orbit (dashed, green line) and orbits computed from samples from the
posterior pdf (grey lines) for the sampling with fixed jitter (top panel) and
the sampling including jitter as a non-linear parameter (bottom panel).
Because we use the same prior samples in each, these look almost identical.
\figname s~\ref{fig:validation-corner-a}--\ref{fig:validation-corner-b} show all
projections of the posterior samples (grey points) and the true, input
parameters (green lines and markers) for the case with fixed jitter and the case
where jitter is treated as a free parameter.
The surviving samples in each case look very similar, as expected.
The typical uncertainties for these simulated data are $\sigma_v \approx
0.15~\kms$; for values of $\ln s \lesssim 3$ (where most are concentrated), this
extra jitter is negligible compared to the uncertainties.
Note that samples above $\ln s \approx 5$ are mostly rejected, indicating that,
as constructed, the uncertainties are purely Gaussian and known.

In both cases, the modes in period-space are narrow with a variety of
separations, as can be seen in the radial-velocity curves plotted in the top
panel.
For small numbers of observations with poor phase-coverage, the posterior pdf
over orbital parameters is extremely complex and structured, but we are still
able to generate samples using \samplername.

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/validation-rv-curves.pdf}
\end{center}
\caption{%
\todo{update this}
In both panels, black points show simulated radial velocity measurements plotted
against Barycentric Modified Julian Date (BMJD) of the observations and dashed
green line shows the true, input orbit that the radial velocity measurements
were drawn from.
Grey curves show orbits computed from 128 samples from, in the top panel, the
posterior pdf with the jitter held fixed at $s^2 = 0$ and, in the bottom panel,
the posterior pdf including jitter as a free parameter.
Several qualitatively different orbital solutions are found over a range of
eccentricities and periods for each case.
This is simply a validation of the method.
\label{fig:validation-rv}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/validation-corner-a.pdf}
\end{center}
\caption{%
\todo{update this}
Projections of the 678 surviving posterior samples when jitter is fixed (grey
points).
The values used to generate the input orbit are shown as green cross-hairs.
\label{fig:validation-corner-a}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/validation-corner-b.pdf}
\end{center}
\caption{%
\todo{update this}
Same as \figname~\ref{fig:validation-corner-a} for the 580 surviving posterior
samples when also sampling over an unknown jitter parameter, $s^2$.
\label{fig:validation-corner-b}}
\end{figure*}

\subsection{Experiment~\arabic{expcounter}: Underestimated uncertainties}
\label{sec:undunc}
\stepcounter{expcounter}

The magnitude of the uncertainties on the individual data points relative to the
amplitude of radial velocity amplitude will change the complexity of the
posterior pdf: Less precise data will admit more qualitatively different
orbital solutions.
The structure and complexity of the posterior pdf (at fixed jitter) will
therefore rely strongly on knowing the uncertainties and instrinsic variability
of the system.
Here we demonstrate this using another simulated radial velocity curve with
smaller signal-to-noise and show that if the uncertainties are underestimated,
the posterior pdf over orbital parameters can look well-constrained but may be
discrepant with the true orbital parameters.
We also show that by simultaneously sampling over an unknown extra variance in
the data (the jitter), we can account for additional, unknown sources of noise.

For this experiment, we use the following parameter values to generate the
simulated data: $P = 103.71~{\rm day}$, $e = 0.313$, $\omega = 250.73^\circ$,
$\phi_0 = 103.01^\circ$, $K = 1.134~\kms$, $v_0 = 8.489~\kms$.
We again uniformly sample 5 observation times over the interval $(0,1095)~{\rm
day}$ and use radial velocity measurement uncertainties drawn from a uniform
distribution over the interval $(0.1, 0.2)~\kms$ (the median true uncertainty is
$\ln \left(\frac{\sigma_v}{\mps}\right) \approx 5$).

When running \samplername\ for this experiment, we consider three cases:
(a) the uncertainties are known and jitter is fixed and ignored ($s^2=0$), (b)
the uncertainties are underestimated by a factor of 8 and jitter is fixed and
ignored ($s^2=0$), and (c) the uncertainties are underestimated by a factor of 8
and we treat the jitter as a free parameter to sample over.
For each case, we again generate $2^{28}$ prior samples over the nonlinear
parameters with a period domain of $(P_{\rm min}, P_{\rm max}) = (16, 8192)~{\rm
day}$ and re-use these prior samples for each case.
In case (c), we generate samples in the jitter by setting
$(\mu_s,\sigma^2_s) = (10,1)$---here we are assuming that we have some suspicion
about the true magnitude of the uncertainties.

\figname~\ref{fig:undunc-rv} shows the simulated data and uncertainties (black
points), the true orbit (dashed, green line), and orbits computed from samples
from the posterior pdf (grey lines) for the three different samplings.
Note that many fewer modes are present in the middle panel (case (b), when the
uncertainties are underestimated).
\figname s~\ref{fig:undunc-corner-a}--\ref{fig:undunc-corner-c} show the
corresponding corner plots for these three cases.
For this data set, when the uncertainties are known, the posterior pdf is highly
multi-modal (case (a)).
When the uncertainties are underestimated, the posterior pdf has fewer modes,
but the true orbital parameters do not appear consistent with any of the
strongest modes (case (b)).
When the uncertainties are underestimated but the jitter is allowed to vary
(case (c)), the model prefers solutions with a finite jitter comparable to the
input true uncertainties ($\ln \left(\frac{\sigma_v}{\mps}\right) \approx 5$).
We have therefore shown that \samplername\ is useful even when uncertainties are
underestimated or the intrinsic variability of a system is unknown.

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/undunc-rv-curves.pdf}
\end{center}
\caption{%
Same as \figname~\ref{fig:validation-rv} for the three cases in this experiment:
(a) known uncertainties and jitter fixed to $s^2 = 0$, (b) underestimated
uncertainties and jitter fixed to $s^2 = 0$, (c) underestimated uncertainties
and jitter allowed to vary.
\label{fig:undunc-rv}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/undunc-corner-a.pdf}
\end{center}
\caption{%
Same as \figname~\ref{fig:validation-corner-a} for case (a) in Experiment 2 where the
uncertainties are known and jitter is fixed to $s^2 = 0$.
46330 samples survive the rejection step.
Henceforth we will drop the angular parameters $\omega$ and $\phi_0$ from the
corner plots to conserve space.
\label{fig:undunc-corner-a}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/undunc-corner-b.pdf}
\end{center}
\caption{%
Same as \figname~\ref{fig:undunc-corner-a} for case (b) in Experiment 2 where the
uncertainties are underestimated by a factor of 8 and jitter is fixed to
$s^2 = 0$.
146 samples survive the rejection step.
\label{fig:undunc-corner-b}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/undunc-corner-c.pdf}
\end{center}
\caption{%
Same as \figname~\ref{fig:undunc-corner-a} for case (c) in Experiment 2 where the
uncertainties are underestimated by a factor of 8 and the jitter is sampled as
a non-linear parameter.
1323 samples survive the rejection step.
\label{fig:undunc-corner-c}}
\end{figure*}

\subsection{Experiment~\arabic{expcounter}: Varying the number of data points}
\label{sec:numpts}
\stepcounter{expcounter}

When the phase coverage of the radial velocity observations is good and the
number of observations is large, the posterior pdf over orbital parameters will
likely be unimodal.
Under these conditions, \samplername\ is a very inefficient sampler for this
problem and will return very few samples (as few as one).
As we have seen in the previous experiments, when the number of data points is
small or the uncertainties are large, the posterior pdf is generally
multi-modal.
He we study the dependence of the complexity of the posterior pdf on the number
of observations by generating simulated observations of a radial velocity curve
and successively removing data points from 11 observations down to 3:
After running \samplername\ with the full 11 observations, we successively
remove 2 data points and re-run the sampling until we are left with 3
observations as input data (a total of 5 consecutive runs).

In detail, we again generate $2^{28}$ prior samples over the nonlinear
parameters with a period domain of $(P_{\rm min}, P_{\rm max}) = (16, 8192)~{\rm
day}$ and re-use these prior samples for each sub-sampling of the data.
We fix the jitter to $s^2 = 0$ and assume that the uncertainties are known.
\figname s~\ref{fig:numpts-rv} shows the simulated data and orbits computed from
posterior samplings.
Starting from the top of \figname~\ref{fig:numpts-rv} with the full set of 11
data points, each panel below has 2 fewer data points than the previous.
The data used for the sampling shown in a given panel are plotted as black
circles and the number of data points used in each panel, $N$, are indicated.
As described in \sectionname~\ref{sec:method}, when the number of surviving
samples $M < M_{\rm min}=128$ after rejection sampling, we either (1) initialize
\emcee\ using the remaining sample(s) if the periods of the surviving sample(s)
are sufficiently close, or (2) re-run \samplername\ with a new set of prior
samples until we have at least $M_{\rm min}$ samples from the posterior pdf.
In all panels, 128 orbits computed from the posterior samples are shown.

The structure in the posterior samples in one projection of the posterior pdf is
shown in the right panels of \figname~\ref{fig:numpts-rv}.
For the cases with 9 and 11 data points, the posterior pdf appears to be
uni-modal.
Multiple modes first appear when $N=7$ and the posterior pdf become more
structured in further sub-samplings of the data until ultimately forming a
harmonic series of modes in the final case of $N=3$.
It's worth emphasizing that even for the case with 3 data points, $<1\%$ of the
prior samples pass the rejection step:
Even 3 radial velocity observations are informative!

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/numpts-rv-curves.pdf}
\end{center}
\caption{%
{\sl Left panels}: Similar to top panel of \figname~\ref{fig:validation-rv}, black
points show \apogee\ radial velocity measurements used to generate samples from
the posterior pdf over orbital parameters sub-sampled from the full set of
simulated data.
Grey curves show orbits compute from 128 samples from the posterior pdf, either
from using \samplername, or, if \samplername\ returns few samples in a small
range, from switching to \emcee\ to continue sampling until 128 samples are
returned.
The number of data points, $N$, and the number of samples that pass the
rejection sampling in the first step of \samplername, $M_{\rm rej}$, are printed
on each panel.
Note that two of the (randomly chosen) observation times are so close that the
markers overlap, so counting the number of data points appears inconsistent with
the reported number.
{\sl Right panels}: A single projection of the posterior samples in each case
showing the log-period, $\ln P$, and eccentricity, $e$.
The structure of the posterior pdf when the number of data points is small is
highly complex but still much more compact than our prior beliefs.
\label{fig:numpts-rv}}
\end{figure*}

\subsection{Experiment~\arabic{expcounter}: Real data for a known binary}
\label{sec:apogee}
\stepcounter{expcounter}

For a more realistic application of \samplername, we choose an \apogee\ target
with a previously identified companion (2M00110648+6609349) but with few radial
velocity measurements (\citealt{Troup:2016}).
\figname~\ref{fig:apogee-rv} shows radial velocity data for the star (black
points). %\footnote{We don't plot the best-fit orbit from
%\citealt{Troup:2016} because the parameter values reported in their work do not
%produce Keplerian orbits that look like reasonable fits to the data.}
Similar to Experiment 1, these data are sparse and have poor phase coverage,
however the time sampling is quite different and is representative of realistic
survey design choices.

We again generate $2^{28}$ prior samples over the nonlinear parameters with a
period domain of $(P_{\rm min}, P_{\rm max}) = (16, 8192)~{\rm day}$ and with
$(\mu_s,\sigma^2_s) = (10.5,1)$, of which 22,313 samples pass our rejection
sampling step.
Over-plotted as grey lines on \figname~\ref{fig:apogee-rv} are 256 orbits
computed from these samples.
From viasualizing these orbits, it appears that there are at least a few
distinct period modes, and a wide variety of eccentricities, represented in the
posterior sampling.

\figname~\ref{fig:apogee-corner} shows projections of all posterior samples in
different parameter combinations.
Here it is clear there are at least three period modes: the dominant mode at $P
\approx 300~{\rm day}$ is broadly consistent with the previously measured period
(\citealt{Troup:2016}), but other modes are clearly present at shorter periods
with low eccentricity and longer periods with higher eccentricity.
Interestingly, we also find that the model prefers having a finite jitter
around $s \approx 116~\mps$ indicating that the uncertainties might be
underestimated by a factor of $\approx 2$.

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/apogee-rv-curves.pdf}
\end{center}
\caption{%
Black points and uncertainties show \apogee\ radial velocity measurements for
the target 2M00110648+6609349.
Grey curves show orbits computed from 256 samples from the posterior pdf
generated with \samplername\ with jitter as a free parameter.
Several qualitatively different orbital solutions are found for this source.
\label{fig:apogee-rv}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/apogee-corner.pdf}
\end{center}
\caption{%
All projections of the 22,313 surviving posterior samples (grey points) with
previously found orbital parameter values shown as the blue cross-hairs
(\citealt{Troup:2016}).
\label{fig:apogee-corner}}
\end{figure*}

\subsection{Experiment \arabic{expcounter}: Prospects for observation planning}
\label{sec:obsplan}
\stepcounter{expcounter}

A noticable difference between the $N=5$ and $N=7$ panels in
\figname~\ref{fig:numpts-rv} is that the posterior pdf collapses significantly
between these cases (from $\gtrsim$20 period modes to 3):
This implies that the two added observations are extremely informative.
Inverting this idea, it also suggests that we can use \samplername\ to (1)
predict the observation time that maximally collapses the posterior pdf for a
previously measured source, and (2) for an expected population of sources, we
can identify the optimal sampling pattern to maximize discovery or
characterization of the sources.
We will explore these ideas in detail in future work, but here we simply show
that the timing of subsequent observations can lead to very different
structure in the posterior samples.

We again simulate a data set of four noisy radial velocity measurements, shown
as black points in the top-left panel of \figname~\ref{fig:obsplan-rv}.
Uncertainties were chosen to match the \apogee\ data ($\sigma_v \approx
0.2~\kms$) and are shown as error bars, but they are often comparable to or
smaller than the marker size.
Top-right panel shows posterior samples produced with \samplername\ again in the
space of log-period $\ln P$ and eccentricity $e$.
The three lower rows all have six observations: the same four from the top row,
but now with two additional observations spaced, in phase, by $\frac{\Delta
\phi}{2 \pi} = 0.04$ but with a different starting phase for the new
observations.
As is shown by the right panels, the observation times of the new observations
can greatly effect the compactness of the posterior pdf.
In particular, the placement of the observations in the bottom row of panels
rules out most of the long-period modes from the top panels, \emph{and} many of
the short-period modes, whereas for the middle two cases the new data are not as
informative.

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/obsplan-rv-curves.pdf}
\end{center}
\caption{%
Similar to \figname~\ref{fig:numpts-rv} but now varying the timing of new
simulated observations relative to the data in the top-left panel.
The top row has four simulated observations and all of the rows below the top
row have two additional observations (six) placed at different times but with
fixed spacing in phase.
The number of data points $N$ and number of samples that survive the rejection
sampling $M$ are shown on each panel.
\label{fig:obsplan-rv}}
\end{figure*}

\section{Discussion} \label{sec:discussion}

We have built a Monte Carlo sampler---\samplername---to draw samples from the
full posterior pdf over orbital parameters for the single-companion
radial-velocity problem.
\samplername\ has nice properties relative to other sampling methods:
(1) It produces fair samplings even when the likelihood (and hence posterior
pdf) is highly multi-modal, (2) the method is based on Simple Monte Carlo, which
is a pure brute-force method, and therefore parallelizes trivially, and (3) the
samplings are guaranteed to be correct under the assumptions presented above
without the need for convergence or other diagnostic checks.
The primary innovation we bring is a separation of the parameters into linear
and nonlinear subsets, such that the brute force is only required in the
nonlinear subspace.
We further capitalize on the problem structure by identifying unimodal and
multi-modal posterior pdfs using the minimum possible width of a likelihood peak
in the period direction, given the time sampling.

Our experiments show that \samplername\ can be used for discovery and
characterization of stellar binaries or exoplanets, even with the presence of
unknown or unreported noise contributions.
It can also be used to generate inputs for a hierarchical inference.
In previous work (\citealt{hoggeccentricity, dfmexopop}) we have shown
that posterior samplings under an interim prior can be importance-sampled
with a hierarchical inference to generate posterior beliefs about the
full population.
These hierarchical inferences are the only population inferences
that properly propagate non-trivial uncertainties at the
individual-system level to the conclusions at the population level.

Interestingly, as we show in Experiment~\ref{sec:numpts}, even very sparse
samplings of the radial-velocity history of a star provide highly
informative posterior pdfs.
The bottom-right panel in \figurename~\ref{fig:numpts-rv} shows a highly
multi-modal posterior pdf, but nonetheless a very informative posterior pdf:
The vast majority of prior pdf samples have been eliminated, and
only a tiny subset of periods, eccentricities, and amplitudes are
consistent with the data.
These posterior pdfs may look like a mess, but they would contribute
extremely valuable information to any hierarchical inference, or
provide a very informative prior pdf for further observing campaigns.

Indeed, one of the purposes for which we built \samplername\ is
observation planning, or cadence evaluation, or survey strategy:
As Experiment~\ref{sec:obsplan} shows, \samplername\ could be used to plan the
times of next observations to maximize their expected information content.
That is beyond the scope of this \documentname, but it is not beyond the scope
of our ambitions.

\samplername\ is based on a set of assumptions, itemized in
\sectionname~\ref{sec:method}.
The method delivers provably correct samplings when these specific assumptions
hold.
Of course, these specific assumptions do \emph{not} hold!
There is never any guarantee that a star's radial-velocity history
is set entirely by a single companion, with no other perturbers or
sources of radial-velocity signal.
More importantly, there are no data sets (to our knowledge) with
perfectly Gaussian noise, and even if there were, the noise variances
could never be perfectly known!
However, the addition of an additional jitter parameter helps
alleviate these issues.

\todo{Clean up Hogg language below...}
Although the single-companion assumption is a severe assumption, it
is pretty-much required for the method to be tractable.
Of course, in reality, it is likely that most stars have thousands or
millions of companions (the Sun does, after all).
Even going to two companions, however, the non-linear parameter space
jumps to eight-dimensional, and (at least) ten-dimensional if there
are companion--companion interactions.
This would be absolutely intractable to sample by brute-force Simple
Monte Carlo; our advice would be to switch to some kind of Markov
Chain method that deals as well as possible with multi-modal
posteriors, such as nested sampling (\citealt{skilling, brewer}).
This change would be associated with the loss of the simple
convergence criterion that Simple Monte Carlo provides: If lots of
samples survive the rejection step, the posterior has been sampled
fairly!
There is no comparably simple way of determining that any nested
sampling is converged.

That said, there is a simple three-body problem that \emph{can} be
solved tractably, with only small modifications:
If the third body is on a very long-period orbit, it appears only
as an overall acceleration (velocity gradient with time).
This can be modeled with just one more parameter, and that parameter
is linear, so it doesn't worsen the prior pdf sampling (which happens
over the nonlinear parameters only).

Actually, the number of linear parameters could be increased
dramatically without any serious loss of performance, since almost all
of the compute time is taken up with the dense sampling in the nonlinear
subspace.
These extra linear parameters could be the extra $v_0$ terms that come
in when, say, the data come from a set of different radial-velocity
programs with different calibrations (as is the case for the recent,
impressive Proxima b discovery; \citealt{proximab}).
Another case for additional linear parameters would be the regressing
out of confounding signals that correlate with housekeeping data,
like, say, radial-velocity shifts that correlate with activity signals
(HOGG CITE?).

Although we have argued that our prior pdf sampling is dense enough,
and---by God---we spend enough time on it, it might not be dense enough
if we push to very short periods.
The problem structure points (in \sectionname~\ref{sec:method})
includes the point that, given a finite time span for the data, there
is a finite width to any period peak in the likelihood function.
This finite width goes like period squared, so at very short periods,
it gets very narrow.
Our prior sampling is uniform in the logarithm of period, or the
density of samples in period goes like inverse period.
If we wanted to make sure a minimal prior sampling was always dense
enough at every period, we should weight it by an additional factor of
inverse period.
A change like this could improve the reliability of the method when the data
are informative, the observations span a long time, and the true
period is short.
For now \samplername\ simply addresses the prior sampling density issues
by using as many prior samples as it possibly can!

All these caveats noted, \emph{by far} the worst assumption made by
\samplername\ is that the noise is Gaussian with known variances:
All data sets show occasional outliers (catastrophic errors), almost
all data sets under-estimate the true radial-velocity errors, and the
fact that the radial-velocity measurments depend on stellar parameters
(the stellar photosphere model, say) leads to added radial-velocity
noise, usually unaccounted for.
What can we do in these cases?
There is nothing we can simply do here, if we want to maintain the
trick of treating the linear and non-linear parameters separately.
Our advice to users who believe that they have additional sources or
forms of noise is to inflate the uncertainty variance estimates and
try to get conservative conclusions about the posterior pdf.

If the only problem is an underestimate of the noise variances, the
factor or offset to be applied to the variances can be promoted to a
non-linear parameter and sampled along with the other nonlinear parameters.
This is probably (just) practical.
If the only problem is occasional outliers, the method could be
modified to do all leave-one-out samplings, take the union, and then
importance sample the results using some ratio of the mixture of
leave-one-out Gaussian likelihoods to some more realistic likelihood
that involves an outlier model (as, for example, we suggest in
\cite{fittingalline}).
These modifications to the method are beyond the scope of this
\documentname\, but (once again) not beyond the scope of our ambitions.

\acknowledgements
This project was started at AstroHackWeek 2016, organized by Kyle
Barbary (UCB) and Phil Marshall (SLAC) at the Berkeley Institute for
Data Science.
It is a pleasure to thank
  Megan Bedell (Chicago),
  Ben Weaver (NOAO),
  and the participants at AstroHackWeek 2016
for valuable discussions.

This research was partially supported by
  the \acronym{NSF} (grants \acronym{IIS-1124794}, \acronym{AST-1312863}, \acronym{AST-1517237}),
  \acronym{NASA} (grant \acronym{NNX12AI50G}),
  and the Moore-Sloan Data Science Environment at \acronym{NYU}.
The data analysis presented in this article was partially performed on
computational resources supported by the Princeton Institute for Computational
Science and Engineering (PICSciE) and the Office of Information Technology's
High Performance Computing Center and Visualization Laboratory at Princeton
University.
This work additionally used the Extreme Science and Engineering Discovery
Environment \citep[XSEDE;][]{Towns:2014}, which is supported by National
Science Foundation grant number ACI-1053575.

This project made use of \sdssiii\ data. Funding for \sdssiii\ has been
provided by the Alfred P. Sloan Foundation, the Participating Institutions, the
National Science Foundation, and the \acronym{U.S.} Department of Energy Office
of Science. The \sdssiii\ web site is \url{http://www.sdss3.org/}.

\sdssiii\ is managed by the Astrophysical Research Consortium for the
Participating Institutions of the \sdssiii\ Collaboration including the
University of Arizona, the Brazilian Participation Group, Brookhaven National
Laboratory, Carnegie Mellon University, University of Florida, the French
Participation Group, the German Participation Group, Harvard University, the
Instituto de Astrofisica de Canarias, the Michigan State/Notre
Dame/\acronym{JINA} Participation Group, Johns Hopkins University, Lawrence
Berkeley National Laboratory, Max Planck Institute for Astrophysics, Max Planck
Institute for Extraterrestrial Physics, New Mexico State University, New York
University, Ohio State University, Pennsylvania State University, University of
Portsmouth, Princeton University, the Spanish Participation Group, University
of Tokyo, University of Utah, Vanderbilt University, University of Virginia,
University of Washington, and Yale University.

\software{The code used in this project is available from
\url{https://github.com/adrn/thejoker} under the MIT open-source software
license. This version was generated at git commit
\texttt{\githash\,(\gitdate)}.
This research additionally utilized:
    \texttt{Astropy} (\citealt{Astropy-Collaboration:2013}),
    \texttt{emcee} (\citealt{Foreman-Mackey:2013}),
    \texttt{IPython} (\citealt{Perez:2007}),
    \texttt{matplotlib} (\citealt{Hunter:2007}),
    and \texttt{numpy} (\citealt{Van-der-Walt:2011}).}

\facility{\sdssiii, \apogee}

\bibliographystyle{aasjournal}
\bibliography{thejoker}

\end{document}
