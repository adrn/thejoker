\documentclass[12pt, preprint]{aastex6}

% to-do list
% ----------
% - zeroth draft

% style notes
% -----------
% - This file generates by Makefile; don't be typing ``pdflatex'' or some bullshit.
% - Line break between sentences to make the git diffs readable.
% - Simple Monte Carlo gets a capital S to indicate that it is a defined thing.
% - Use \, as a multiply operator.
% - Reserve () for function arguments; use [] or {} for outer shit.
% - Always prior pdf or posterior pdf, never prior or posterior (that's your arse).

\include{gitstuff}

% fix aastex
\setlength{\parindent}{1.4em}
\linespread{1.15} % close to 10/13 spacing in ``manuscript''
\setlength{\parskip}{0ex}
\makeatletter % you know you are living your life wrong when you need to do this
\def\revtex@pageid{%
 \xdef\@thefnmark{\null}%
 \@footnotetext{%
  This \revtex@genre\space was prepared with the
  \revtex@org\space \LaTeX\ macros v\revtex@ver, with modifications by David~W.~Hogg.%
 }%
}%
\def\abstractname{Abstract}%
\makeatother
\sloppy\sloppypar\frenchspacing

% packages
\usepackage{amsmath}
\hypersetup{backref,breaklinks,colorlinks,citecolor=black}
% \usepackage[backref,breaklinks,colorlinks,citecolor=black]{hyperref}
% \usepackage[all]{hypcap}
% \renewcommand*{\backref}[1]{[#1]}

% define macros for text
\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\acronym}[1]{{\small{#1}}}
\newcommand{\apogee}{\project{\acronym{APOGEE}}}
\newcommand{\sdssiii}{\project{\acronym{SDSS-III}}}
\newcommand{\samplername}{\project{The~Joker}}
\newcommand{\emcee}{\project{emcee}}
\newcommand{\dr}{\acronym{DR13}}

% define macros for math
\newcommand{\meterspersecond}{\mathrm{m\,s^{-1}}}
\newcommand{\asini}{\ensuremath{a_1\,\sin i}}
\newcommand{\given}{\,|\,}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\transpose}[1]{{#1}^{\mathsf{T}}}
\newcommand{\inv}[1]{{#1}^{-1}}
\newcommand{\msun}{\mathrm{M}_\odot}
\newcommand{\bs}[1]{\boldsymbol{#1}}

% TODO
\newcommand{\todoapw}[1]{{\color{red}APW TODO: #1}}
\newcommand{\todohogg}[1]{{\color{green}Hogg TODO: #1}}

\begin{document}

\title{\samplername: A custom Monte Carlo sampler \\
  for binary-star and exoplanet radial velocity data}
\author{Adrian~M.~Price-Whelan\altaffilmark{\pu,\adrn},
        David~W.~Hogg\altaffilmark{\ccpp,\mpia},
        Daniel~Foreman-Mackey\altaffilmark{\uw,\sagan},
        Hans-Walter~Rix\altaffilmark{\mpia}
}

% Affiliations
\newcommand{\pu}{1}
\newcommand{\adrn}{2}
\newcommand{\ccpp}{3}
\newcommand{\mpia}{4}
\newcommand{\uw}{5}
\newcommand{\sagan}{6}

\altaffiltext{\pu}{Department of Astrophysical Sciences,
                   Princeton University, Princeton, NJ 08544, USA}
\altaffiltext{\adrn}{To whom correspondence should be addressed:
                     \texttt{adrn@princeton.edu}}
\altaffiltext{\ccpp}{Center for Cosmology and Particle Physics,
                     Department of Physics,
                     New York University, 4 Washington Place,
                     New York, NY 10003, USA}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie,
                     K\"onigstuhl 17, D-69117 Heidelberg, Germany}
\altaffiltext{\uw}{Astronomy Department, University of Washington,
                   Seattle, WA 98195, USA}
\altaffiltext{\sagan}{Sagan Fellow}

\begin{abstract}
% Context
Given sparse radial-velocity measurements of a star, there are often
many qualitatively different stellar or exoplanet companion orbit
models that are consistent with the data.
The consequent multimodality of the likelihood function leads to
extremely challenging search, optimization, and MCMC posterior
sampling in the space of orbital parameters.
% Aims
Here we create a custom-built Monte Carlo sampler that can produce a
posterior sampling for orbital parameters given even small numbers of
noisy radial-velocity measurements (and hence a very complex likelihood
function).
The goal is to obtain provably correct samplings in the space of
orbital parameters.
% Methods
We build a variant of Simple Monte Carlo sampling, in which we densely
sample the non-linear orbital parameters, and perform rejection
sampling using a marginalized likelihood, marginalizing out the linear
orbital parameters.
In practice and generically, the sampling obtained by the Simple Monte
Carlo is---in the case of sparse or uninformative data---substantial
and multimodal, or else---in the case of informative
data---insubstantial but unimodal.
In the unimodal case, we follow the Simple Monte Carlo with standard
MCMC to make the sampling more substantial.
% Results
The method produces correct samplings in orbital
parameters for (good) data sets that include as few as three noisy time
points.
We give some examples that show how the posterior probability depends
extremely strongly on the number and time coverage of the
observations.
We discuss extensions to the method that could handle issues with the
noise model or outliers.
\end{abstract}

\keywords{
  binaries: spectroscopic
  ---
  methods: data analysis
  ---
  methods: statistical
  ---
  planets and satellites: fundamental parameters
  ---
  surveys
  ---
  techniques: radial velocities
}

\section{Introduction} \label{sec:intro}

Precise radial-velocity measurements of stars have transformed
astrophysics in the last decades:
They have permitted the discovery of the first planets around other stars,
including especially the unanticipated but common ``hot Jupiters,''
and been used to discover or confirm hundreds
(perhaps thousands?) of planets.
Radial velocity measurements have also been used to find substellar,
degenerate, and black-hole companions to more normal stars, and hold
the promise of delivering the full population statistics for binary
(and trinary) star systems.

With many new stellar spectroscopic surveys operating or under
construction, we expect to have good quality spectra for millions
of stars in the next few years.
Most of these surveys have at least some targets---and many have many
targets---that are observed multiple times.
These surveys can (as an auxilliary or primary goal of their observing
strategies) generate discoveries of planetary, substellar, and stellar
companions.
These discoveries, in turn, will feed population inferences, follow-up
programs, and projects to refine precise stellar models.

However, when radial-velocity observations are not designed with
unambiguous detection and discovery in mind, usually there are
multiple possible binary-star models that are consistent with any
small number of radial-velocity measurements that show stellar
acceleration.
That is, a small number of (even very good) radial velocity
measurements will lead to posterior beliefs about companion orbits and
masses that put substantial plausibility onto multiple qualitatively
different solutions, or (in other words) create a likelihood function
that is highly multi-model in the relevant parameter spaces.
There are currently no safe methods known for exploring these highly
multimodal functions and delivering correct posterior samplings and
reliable probabilistic statements about detection and
characterization.

Here we make an attempt at correcting these problems.
Our approach is to build custom posterior sampling methods that
capitalize on the structure of the binary-star (or star--exoplanet)
kinematics to create provably---or highly probably---correct
samplings.

The structure of the paper is as follows:
We state clearly our assumptions, and demonstrate that we have a
method that is correct under those assumptions.
We perform experiments with the method to understand its properties
and limitations.
We finish by discussing the value of the method, and the changes we
would have to make if we weakened our assumptions, or if we don't
weaken our assumptions but they indeed prove to be far from correct.

\section{Assumptions and method}

In order to set up a well-posed problem and build a path to a
definite solution, we make a set of non-trivial assumptions about the
stellar systems we will use and observations thereof.
\begin{itemize}
\item We assume that we have measurements of the radial velocity of a
  star, and that the time dependence of the expectation of that radial
  velocity is well described by the gravitational orbit of a pair of
  point masses (the two-body problem). We assume that the times are
  (effectively) perfectly known, and in an inertial frame (for
  example, Solar-System barycentric MJD).
\item We assume that each star has exactly one companion, and that the
  radial-velocity measurements are not contaminated by nor affected by
  any other bodies. Since we permit the effective mass of the
  exactly-one companion to go to zero, this assumption is really that
  the star has zero or one companion.
\item We assume that the noise contributions to individual
  radial-velocity measurements are well described as draws from
  zero-mean normal (Gaussian) distributions with correctly known
  variances. We assume that there are no outliers.
\item In addition to all these, we put particular, fairly sensible
  prior probability density functions on all the orbital parameters,
  described below.
\end{itemize}
Each of these assumptions can be challenged, and in particular we
expect some stars to have additional companions, and we expect there
to be outliers and unaccounted sources of noise.
We will return to these assumptions, and the consequences of relaxing
them, in the Discussion Section.

In the two-body celestial mechanics problem (\citealt{Kepler:1609}; and here we
are working in a parameterization similar to that of \citealt{Murray:2010}), and
under our above-stated assumptions, the radial-velocity expectation can be
parameterized by six parameters, which we choose to be period $P$, projected
semi-major axis of the observed star $\asini$, a phase $\phi_0$ corresponding to
a time of pericenter passage, the eccentricity $e$, an argument of perihelion
$\omega$, and a constant system barycenter radial velocity $v_0$.
The radial velocity $v$ at time $t$ is then given by (see also
equation~63 in \citealt{Murray:2010})
\begin{equation}
  v(t;\theta) = v_0 + \kappa\,[\cos(\omega + f) + e\,\cos\omega]
\end{equation}
where the $\theta$ represents a blob of all the free parameters,
$\kappa$ is the velocity semi-amplitude and $f$ is the true anomaly
given by
\begin{align}
  \kappa = \frac{2\pi\,\asini}{P\,\sqrt{1-e^2}}\\
  \cos f &= \frac{\cos E - e}{1 - e\, \cos E}
\end{align}
and the eccentric anomaly, $E$, must be solved for with the mean
anomaly, $M$,
\begin{align}
  M = \frac{2\pi\, t}{P} - \phi_0\\
  M = E - e\,\sin E \quad .
\end{align}
Of these parameters, four ($P$, $\phi_0$, $e$, $\omega$) are
non-linearly related to the radial-velocity expectation, and two
($\asini$, $v_0$) are linearly related.

Fundamentally, our method is to perform \emph{Simple Monte Carlo} in
the non-linear parameters, and analytically marginalize over the linear
parameters.
The method capitalizes on the following aspects of the problem
structure:
\begin{itemize}
\item There are both linear and non-linear parameters, and we can
  treat them differently; in particular, it is possible to
  analytically marginalize the linear parameters (provided that the
  noise model is pleasant and the prior pdf is conjugate).
\item There is a finite, time-sampling-imposed minimum size or
  resolution---in the period direction---of any features in the
  likelihood function. That is, there cannot be arbitrarily narrow
  modes in the multimodal posterior pdf.
\end{itemize}

Simple Monte Carlo is a method in which the prior pdf is densely
sampled, and then many of the samples are rejected by a
rejection-sampling step that uses the likelihood as the rejection
scalar.
The rejection step works as follows:
\begin{enumerate}
\item For each sample $k$ in the prior pdf sampling there is a
  likelihood value $L_k$ (a probability for the data given the
  parameters, not logarithmic).
\item There is a maximum value $L_{\rm max}$ that is the largest value of
  $L_k$ found across all of the samples in the entire sampling.
\item For each sample $k$, choose a random number $r_k$ between 0 and
  $L_{\rm max}$
\item Reject the sample $k$ if $L_k < r_k$.
\item The number of samples that survive the rejection is (hereafter) $M$.
\end{enumerate}
Note that this algorithm is guaranteed to produce at least one
surviving sample; of course if only one sample survives (or any very
small number), the sampling will not guaranteed to be fair.
That said, if the original sampling of the prior pdf is dense enough
that many survive the rejection step, the surviving samples do
constitute a fair sampling from the posterior pdf.

Our prior pdf in the non-linear parameters is very simple:
\begin{align}
    p(\ln P) &= \mathcal{U}(\ln P_{\rm min}, \ln P_{\rm max})\\
    p(\omega) &= \mathcal{U}(0, 2\pi) ~ [{\rm rad}]\\
    p(\phi_0) &= \mathcal{U}(0, 2\pi) ~ [{\rm rad}]\\
    p(e) &= {\rm Beta}(a, b) = \frac{\Gamma(a+b)}{\Gamma(a) \, \Gamma(b)} \, e^{a-1} \, [1 - e]^{b-1}
\end{align}
where $\mathcal{U}(x_1, x_2)$ is the uniform distribution over the
domain $(x_1, x_2)$ and the prior over eccentricity is the Beta
distribution with $a=0.867$, $b=3.03$ \citep{Kipping:2013}.
In different experiments we use different values for hyperparameters
$P_{\rm min}$ and $P_{\rm max}$; we are explicit about our choices in
each of the experiments described below.
We sample the prior pdf directly and explicitly with standard
\project{numpy.random} calls (\citealt{Van-der-Walt:2011}).
In practice we usually take $2^{28}$ (that's about a quarter billion)
samples in the prior-pdf sampling. Holy fuck that's a lot!

The unmarginalized likelihood function $L$ is
\begin{equation}
\ln L = -\frac{1}{2}\,\sum_{n=1}^N \frac{[v_n - v(t_n;\theta)]^2}{\sigma_n^2}
\end{equation}
where $n$ indexes the individual data points $v_n$, $v(t)$ is the
radial velocity prediction at time $t$ given the parameters $\theta$, the
data-point times are the $t_n$, and the $\sigma_n^2$ is the (presumed
correctly known) Gaussian noise variance for data point $n$.
Note that the form of this likelihood function is set entirely by
the assumptions, given above.

We rejection-sample, however, using a marginalized likelihood, where
we analytically marginalize out the linear parameters ($\asini$,
$v_0$).
We construct a $N\times 2$ design matrix consisting of a column of
unit-$[\asini]$ predictions (given the non-linear parameters) and a
column of ones.
We perform standard linear least-square fitting with this design
matrix to obtain the best-fit values for the two linear parameters,
and the standard $2\times 2$ linear-fitting covariance matrix $C_k$ for their
uncertainties.
With these, we can construct---for each prior sample---the marginalized likelihood $Q_k$
\begin{equation}
\ln Q_k = -\frac{1}{2}\,\sum_{n=1}^N \frac{[v_n - v(t_n;\theta_k)]^2}{\sigma_n^2} -\frac{1}{2}\,\ln ||C_k||
\end{equation}
where the prediction $v(t_n;\theta_k)$ is taken at the best-fit values
of the linear parameters given sample $k$ of the non-linear
parameters, and the log-determinant term accounts for the volume in
the marginalization integral.
The marginalization assumes that the prior pdfs on the linear parameters
are very broad and Gaussian---or
at least very flat over the range of relevance---and that they do not depend
on the nonlinear parameters in any way (which is a substantial restriction;
see the Discussion).
These $Q_k$ are used in the rejection sampling algorithm described above
as Simple Monte Carlo.

There are three possible outcomes at the end of the rejection
sampling, based on two thresholds:
We set a minimum number of samples $M_{\rm min}=128$.
We also set a period resolution $\Delta = [4\,P^2] / [2\pi\,T]$, (with
$P$ set to the median period across the surviving samples and $T$ set to
the time span of the data; max minus min).
This $\Delta$ is an expansion of the period
resolution expected from an information-theory (sampling theorems) perspective.
The three possible outcomes are:
\begin{itemize}
\item $M\geq M_{\rm min}$ samples survive the rejection.
  In this case, we are done.
\item $M<M_{\rm min}$ samples survive the rejection, and these samples
  have a root-variance (rms) in the period parameter $P$ that is
  smaller than $\Delta$.
  In this case, we use the surviving samples (or sample) to
  initialize a MCMC sampling using the \emcee\ package (\citealt{emcee}).
  We sample the
  prior densely enough initially that if only a few samples survive,
  we are fairly confident that the data are informative enough that
  the posterior pdf is approximately unimodal for our purposes. That's
  an assumption!
\item $M<M_{\rm min}$ samples survive the rejection, and these samples
  span a period range larger than $\Delta$.
  In this case, we iterate the Simple
  Monte Carlo, starting from new prior-pdf samplings, concatenating
  the surviving samples, until the full set of surviving samples is
  larger than $M_{\rm min}$. This is expensive!
\end{itemize}
When we trigger the intialization and operation of \emcee, we do the following:
\begin{enumerate}
\item Randomly generate $M_{\rm min}$ sets of parameters $\theta_m$
  (linear and nonlinear parameters) in a small, Gaussian ball around
  the highest-$Q_k$ sample from the Simple Monte Carlo.
\item Run \emcee\ on this ensemble as per the instructions written on
  the side of the \emcee\ packaging (\citealt{emcee}) for $2^{16}$ steps.
\item Take the final state of the $M_{\rm min}$-element ensemble as a
  fair sampling of the posterior pdf.
\end{enumerate}
This procedure ensures that no matter what path we take, we end up with
at least $M_{\rm min}$ samples from the posterior for any input data.

\section{Experiments and results}

In what follows, we use spectroscopic data from Data Release 13 (DR13;
\citealt{SDSS-Collaboration:2016}) of the Apache Point Obsevatory Galactic
Evolution Experiment (\apogee; \citealt{Majewski:2015}) in a series of
experiments that demonstrate the robustness and utility of \samplername.
\apogee\ is one of the four sub-surveys of the Sloan Digital Sky Survey-III
(SDSS-III; \citealt{Eisenstein:2011}) and utilized a new infrared spectrograph
to obtain H-band spectra for over 160,000 stars throughout the Galaxy.
From these spectra, high-precision radial velocities, chemical abundances, and
stellar parameters have been derived and released as a part of DR13
(\citealt{Holtzman:2015,Nidever:2015}).

As a part of the observing strategy of \apogee, most stars are observed multiple
times and binned by day into ``visit'' spectra.
Though a typical star is only observed a few times, (1) at least one pair of
visits are separated by one month or longer, and (2) thousands of stars have
been observed more than 10 times (for a more detailed look at the cadence and
number of visits for \apogee\ stars, see Figure~1 in \citealt{Troup:2016}).
Radial velocities (and stellar parameters) are derived for each of the visit
spectra, affording a sparse and sporadic time-domain sampling of the radial
velocity variations of most stars in the survey.
This time-domain information was recently used to identify a sample of candidate
stellar and substellar companions to \apogee\ stars (\citealt{Troup:2016}).

This search was conducted after data quality and data \emph{quantity} cuts that
were designed to keep the number of data points larger than the number of
parameters in the model.
In their case, the model parameters are six Keplerian orbital parameters plus a
long-term (linear) velocity trend (seven in total).
Under this criterion, stars with fewer than eight visits were rejected from
consideration, leaving $\approx$15,000 stars.
For each of the remaining stars, the radial velocity curves are searched for
significant periods, which are then used to initialize $\chi^2$ fits of a
Keplerian orbit using a custom least-squares fitter \todoapw{cite De Lee even
though we don't use it?}.
In cases where multiple significant periods are found, the parameters obtained
from the fit with the best modified $\chi^2$ value are retained (modulo a number
of other considerations described in Section~3.3.4 of \citealt{Troup:2016}).

The complexity of this pipeline and logic needed to identify a single optimal
set of orbital parameters from a set of solutions highlights the fact that the
likelihood function for a Keplerian orbit model is generically multi-modal.
When there are few data points or poor phase coverage this is especially true.
While useful for searching for new candidate binaries, this pipeline does not
easily fit within hierarchical probabilistic modeling of the population of
companions.

In Experiment 1, we use DR13 data for an \apogee\ star with a companion
(identified by \citealt{Troup:2016}) to demonstrate that the posterior pdf over
Keplerian orbital parameters can be highly multi-modal by using \samplername\ to
generate samples from this distribution.
In Experiment 2, we use DR13 data for an \apogee\ star with better radial
velocity phase coverage and more observations and show how the complexity of the
posterior pdf increases as data points are artificially deleted from the
analysis.
\todoapw{Experiment 3 is what?}

\subsection{Experiment 1: Sampling a highly multi-model posterior pdf for a
known companion}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/exp1-rv-curves.pdf}
\end{center}
\caption{%
Black points show \apogee\ radial velocity measurements plotted against
Barycentric Modified Julian Date (BMJD) of the observations.
Grey curves show orbits compute from 512 samples from the posterior pdf for
these data.
Note that several qualitatively different orbital solutions are found over a
range of eccentricities and periods.
\label{fig:exp1-rv}}
\end{figure*}

\begin{figure*}[p]
\begin{center}
\includegraphics[width=\textwidth]{figures/exp1-corner.pdf}
\end{center}
\caption{%
Suh.
\label{fig:exp1-corner}}
\end{figure*}

\subsection{Experiment 2: ...}

Show results as a function of $N$.

\subsection{Experiment 3: ...}

Show switch-over from SMC to \emcee.

\section{Discussion}

What did we find?

What can this system be used for? Discovery, characterization, and
hierarchial inference.

HOGG The assumption of single companion has the following issues...

HOGG The assumption that the linear-parameter prior doesn't depend
on the nonlinear parameters is absurd! Why?

Of the assumptions, probably the most severe is the Gaussian noise
with known variance. \textbf{This is wrong, very wrong!} Ideas about
ameliorating this, and what those options would cost us. Advice for
those using the system despite these issues.

\acknowledgements
It is a pleasure to thank
  Ben Weaver (NOAO),
for valuable discussions.
This research was partially supported by [many grants].
This project was started at AstroHackWeek 2016, organized by Kyle
Barbary (UCB) and Phil Marshall (SLAC) at the Berkeley Institute for
Data Science.

The data analysis presented in this article was partially performed on
computational resources supported by the Princeton Institute for Computational
Science and Engineering (PICSciE) and the Office of Information Technology's
High Performance Computing Center and Visualization Laboratory at Princeton
University.
This work additionally used the Extreme Science and Engineering Discovery
Environment \citep[XSEDE;][]{Towns:2014}, which is supported by National
Science Foundation grant number ACI-1053575.

This project made use of \sdssiii\ data. Funding for \sdssiii\ has been provided
by the Alfred P. Sloan Foundation, the Participating Institutions, the National
Science Foundation, and the \acronym{U.S.} Department of Energy Office of
Science. The \sdssiii\ web site is \url{http://www.sdss3.org/}.

\sdssiii\ is managed by the Astrophysical Research Consortium for the
Participating Institutions of the \sdssiii\ Collaboration including the
University of Arizona, the Brazilian Participation Group, Brookhaven National
Laboratory, Carnegie Mellon University, University of Florida, the French
Participation Group, the German Participation Group, Harvard University, the
Instituto de Astrofisica de Canarias, the Michigan State/Notre
Dame/\acronym{JINA} Participation Group, Johns Hopkins University, Lawrence
Berkeley National Laboratory, Max Planck Institute for Astrophysics, Max Planck
Institute for Extraterrestrial Physics, New Mexico State University, New York
University, Ohio State University, Pennsylvania State University, University of
Portsmouth, Princeton University, the Spanish Participation Group, University of
Tokyo, University of Utah, Vanderbilt University, University of Virginia,
University of Washington, and Yale University.

\software{The code used in this project is available from
\url{https://github.com/adrn/thejoker} under the MIT open-source software
license. This version of the paper was generated with git commit
\texttt{\githash~(\gitdate)}.
This research additionally utilized:
    \texttt{Astropy} (\citealt{Astropy-Collaboration:2013}),
    \texttt{emcee} (\citealt{Foreman-Mackey:2013}),
    \texttt{IPython} (\citealt{Perez:2007}),
    \texttt{matplotlib} (\citealt{Hunter:2007}),
    and \texttt{numpy} (\citealt{Van-der-Walt:2011}).}

\bibliographystyle{apj}
\bibliography{thejoker}

\end{document}
